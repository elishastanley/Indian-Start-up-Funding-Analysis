{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Indian Start-up Funding Analysis (2018 - 2021)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing all necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "from dotenv import dotenv_values\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "warnings. filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Loading**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading from csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Round/Series</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Location</th>\n",
       "      <th>About Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TheCollegeFever</td>\n",
       "      <td>Brand Marketing, Event Promotion, Marketing, S...</td>\n",
       "      <td>Seed</td>\n",
       "      <td>250000</td>\n",
       "      <td>Bangalore, Karnataka, India</td>\n",
       "      <td>TheCollegeFever is a hub for fun, fiesta and f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Happy Cow Dairy</td>\n",
       "      <td>Agriculture, Farming</td>\n",
       "      <td>Seed</td>\n",
       "      <td>₹40,000,000</td>\n",
       "      <td>Mumbai, Maharashtra, India</td>\n",
       "      <td>A startup which aggregates milk from dairy far...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MyLoanCare</td>\n",
       "      <td>Credit, Financial Services, Lending, Marketplace</td>\n",
       "      <td>Series A</td>\n",
       "      <td>₹65,000,000</td>\n",
       "      <td>Gurgaon, Haryana, India</td>\n",
       "      <td>Leading Online Loans Marketplace in India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PayMe India</td>\n",
       "      <td>Financial Services, FinTech</td>\n",
       "      <td>Angel</td>\n",
       "      <td>2000000</td>\n",
       "      <td>Noida, Uttar Pradesh, India</td>\n",
       "      <td>PayMe India is an innovative FinTech organizat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eunimart</td>\n",
       "      <td>E-Commerce Platforms, Retail, SaaS</td>\n",
       "      <td>Seed</td>\n",
       "      <td>—</td>\n",
       "      <td>Hyderabad, Andhra Pradesh, India</td>\n",
       "      <td>Eunimart is a one stop solution for merchants ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Company Name                                           Industry  \\\n",
       "0  TheCollegeFever  Brand Marketing, Event Promotion, Marketing, S...   \n",
       "1  Happy Cow Dairy                               Agriculture, Farming   \n",
       "2       MyLoanCare   Credit, Financial Services, Lending, Marketplace   \n",
       "3      PayMe India                        Financial Services, FinTech   \n",
       "4         Eunimart                 E-Commerce Platforms, Retail, SaaS   \n",
       "\n",
       "  Round/Series       Amount                          Location  \\\n",
       "0         Seed       250000       Bangalore, Karnataka, India   \n",
       "1         Seed  ₹40,000,000        Mumbai, Maharashtra, India   \n",
       "2     Series A  ₹65,000,000           Gurgaon, Haryana, India   \n",
       "3        Angel      2000000       Noida, Uttar Pradesh, India   \n",
       "4         Seed            —  Hyderabad, Andhra Pradesh, India   \n",
       "\n",
       "                                       About Company  \n",
       "0  TheCollegeFever is a hub for fun, fiesta and f...  \n",
       "1  A startup which aggregates milk from dairy far...  \n",
       "2          Leading Online Loans Marketplace in India  \n",
       "3  PayMe India is an innovative FinTech organizat...  \n",
       "4  Eunimart is a one stop solution for merchants ...  "
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading 2018 funds data\n",
    "data_2018 = pd.read_csv('data\\startup_funding2018.csv')\n",
    "\n",
    "# Data preview\n",
    "data_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company/Brand</th>\n",
       "      <th>Founded</th>\n",
       "      <th>HeadQuarter</th>\n",
       "      <th>Sector</th>\n",
       "      <th>What it does</th>\n",
       "      <th>Founders</th>\n",
       "      <th>Investor</th>\n",
       "      <th>Amount($)</th>\n",
       "      <th>Stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bombay Shaving</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ecommerce</td>\n",
       "      <td>Provides a range of male grooming products</td>\n",
       "      <td>Shantanu Deshpande</td>\n",
       "      <td>Sixth Sense Ventures</td>\n",
       "      <td>$6,300,000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ruangguru</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Edtech</td>\n",
       "      <td>A learning platform that provides topic-based ...</td>\n",
       "      <td>Adamas Belva Syah Devara, Iman Usman.</td>\n",
       "      <td>General Atlantic</td>\n",
       "      <td>$150,000,000</td>\n",
       "      <td>Series C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eduisfun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Edtech</td>\n",
       "      <td>It aims to make learning fun via games.</td>\n",
       "      <td>Jatin Solanki</td>\n",
       "      <td>Deepak Parekh, Amitabh Bachchan, Piyush Pandey</td>\n",
       "      <td>$28,000,000</td>\n",
       "      <td>Fresh funding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HomeLane</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Interior design</td>\n",
       "      <td>Provides interior designing solutions</td>\n",
       "      <td>Srikanth Iyer, Rama Harinath</td>\n",
       "      <td>Evolvence India Fund (EIF), Pidilite Group, FJ...</td>\n",
       "      <td>$30,000,000</td>\n",
       "      <td>Series D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nu Genes</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>AgriTech</td>\n",
       "      <td>It is a seed company engaged in production, pr...</td>\n",
       "      <td>Narayana Reddy Punyala</td>\n",
       "      <td>Innovation in Food and Agriculture (IFA)</td>\n",
       "      <td>$6,000,000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company/Brand  Founded HeadQuarter           Sector  \\\n",
       "0  Bombay Shaving      NaN         NaN        Ecommerce   \n",
       "1       Ruangguru   2014.0      Mumbai           Edtech   \n",
       "2        Eduisfun      NaN      Mumbai           Edtech   \n",
       "3        HomeLane   2014.0     Chennai  Interior design   \n",
       "4        Nu Genes   2004.0   Telangana         AgriTech   \n",
       "\n",
       "                                        What it does  \\\n",
       "0         Provides a range of male grooming products   \n",
       "1  A learning platform that provides topic-based ...   \n",
       "2            It aims to make learning fun via games.   \n",
       "3              Provides interior designing solutions   \n",
       "4  It is a seed company engaged in production, pr...   \n",
       "\n",
       "                                Founders  \\\n",
       "0                     Shantanu Deshpande   \n",
       "1  Adamas Belva Syah Devara, Iman Usman.   \n",
       "2                          Jatin Solanki   \n",
       "3           Srikanth Iyer, Rama Harinath   \n",
       "4                 Narayana Reddy Punyala   \n",
       "\n",
       "                                            Investor     Amount($)  \\\n",
       "0                               Sixth Sense Ventures    $6,300,000   \n",
       "1                                   General Atlantic  $150,000,000   \n",
       "2     Deepak Parekh, Amitabh Bachchan, Piyush Pandey   $28,000,000   \n",
       "3  Evolvence India Fund (EIF), Pidilite Group, FJ...   $30,000,000   \n",
       "4           Innovation in Food and Agriculture (IFA)    $6,000,000   \n",
       "\n",
       "           Stage  \n",
       "0            NaN  \n",
       "1       Series C  \n",
       "2  Fresh funding  \n",
       "3       Series D  \n",
       "4            NaN  "
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading 2019 funds data\n",
    "data_2019 = pd.read_csv('data\\startup_funding2019.csv')\n",
    "\n",
    "# Data preview\n",
    "data_2019.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "('08001', '[08001] [Microsoft][ODBC SQL Server Driver][DBNETLIB]SQL Server does not exist or access denied. (17) (SQLDriverConnect); [08001] [Microsoft][ODBC SQL Server Driver][DBNETLIB]ConnectionOpen (Connect()). (53)')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[249], line 18\u001b[0m\n\u001b[0;32m     11\u001b[0m connection_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDRIVER=\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;124mSQL Server\u001b[39m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m; \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124m                    SERVER=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mserver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124m                    DATABASE=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatabase\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124m                    UID=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00musername\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124m                    PWD=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassword\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Connecting to the server\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[43mpyodbc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection_string\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOperationalError\u001b[0m: ('08001', '[08001] [Microsoft][ODBC SQL Server Driver][DBNETLIB]SQL Server does not exist or access denied. (17) (SQLDriverConnect); [08001] [Microsoft][ODBC SQL Server Driver][DBNETLIB]ConnectionOpen (Connect()). (53)')"
     ]
    }
   ],
   "source": [
    "# Loading environment variables from .env file\n",
    "environment_variables = dotenv_values('.env')\n",
    "\n",
    "# Getting the values for the credentials set in the .env' file\n",
    "server = environment_variables.get(\"SERVER\")\n",
    "database = environment_variables.get(\"DATABASE\")\n",
    "username = environment_variables.get(\"USERNAME\")\n",
    "password = environment_variables.get(\"PASSWORD\")\n",
    "\n",
    "# Creating a connection string\n",
    "connection_string = f\"DRIVER={{SQL Server}}; \\\n",
    "                    SERVER={server}; \\\n",
    "                    DATABASE={database}; \\\n",
    "                    UID={username}; \\\n",
    "                    PWD={password};\"\n",
    "\n",
    "# Connecting to the server\n",
    "connection = pyodbc.connect(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Brand</th>\n",
       "      <th>Founded</th>\n",
       "      <th>HeadQuarter</th>\n",
       "      <th>Sector</th>\n",
       "      <th>What_it_does</th>\n",
       "      <th>Founders</th>\n",
       "      <th>Investor</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Stage</th>\n",
       "      <th>column10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aqgromalin</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>AgriTech</td>\n",
       "      <td>Cultivating Ideas for Profit</td>\n",
       "      <td>Prasanna Manogaran, Bharani C L</td>\n",
       "      <td>Angel investors</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Krayonnz</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>EdTech</td>\n",
       "      <td>An academy-guardian-scholar centric ecosystem ...</td>\n",
       "      <td>Saurabh Dixit, Gurudutt Upadhyay</td>\n",
       "      <td>GSF Accelerator</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>Pre-seed</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PadCare Labs</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Hygiene management</td>\n",
       "      <td>Converting bio-hazardous waste to harmless waste</td>\n",
       "      <td>Ajinkya Dhariya</td>\n",
       "      <td>Venture Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pre-seed</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCOME</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Escrow</td>\n",
       "      <td>Escrow-as-a-service platform</td>\n",
       "      <td>Ritesh Tiwari</td>\n",
       "      <td>Venture Catalysts, PointOne Capital</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gramophone</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Indore</td>\n",
       "      <td>AgriTech</td>\n",
       "      <td>Gramophone is an AgTech platform enabling acce...</td>\n",
       "      <td>Ashish Rajan Singh, Harshit Gupta, Nishant Mah...</td>\n",
       "      <td>Siana Capital Management, Info Edge</td>\n",
       "      <td>340000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company_Brand  Founded HeadQuarter              Sector  \\\n",
       "0    Aqgromalin   2019.0     Chennai            AgriTech   \n",
       "1      Krayonnz   2019.0   Bangalore              EdTech   \n",
       "2  PadCare Labs   2018.0        Pune  Hygiene management   \n",
       "3         NCOME   2020.0   New Delhi              Escrow   \n",
       "4    Gramophone   2016.0      Indore            AgriTech   \n",
       "\n",
       "                                        What_it_does  \\\n",
       "0                       Cultivating Ideas for Profit   \n",
       "1  An academy-guardian-scholar centric ecosystem ...   \n",
       "2   Converting bio-hazardous waste to harmless waste   \n",
       "3                       Escrow-as-a-service platform   \n",
       "4  Gramophone is an AgTech platform enabling acce...   \n",
       "\n",
       "                                            Founders  \\\n",
       "0                    Prasanna Manogaran, Bharani C L   \n",
       "1                   Saurabh Dixit, Gurudutt Upadhyay   \n",
       "2                                    Ajinkya Dhariya   \n",
       "3                                      Ritesh Tiwari   \n",
       "4  Ashish Rajan Singh, Harshit Gupta, Nishant Mah...   \n",
       "\n",
       "                              Investor    Amount     Stage column10  \n",
       "0                      Angel investors  200000.0      None     None  \n",
       "1                      GSF Accelerator  100000.0  Pre-seed     None  \n",
       "2                       Venture Center       NaN  Pre-seed     None  \n",
       "3  Venture Catalysts, PointOne Capital  400000.0      None     None  \n",
       "4  Siana Capital Management, Info Edge  340000.0      None     None  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading 2020 funds data\n",
    "data_2020 = pd.read_sql_query(\n",
    "    \"SELECT * FROM LP1_startup_funding2020\", connection)\n",
    "\n",
    "# Saving the DataFrame to a CSV file\n",
    "data_2020.to_csv('data/startup_funding2020.csv', index=False)\n",
    "\n",
    "data_2020.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Brand</th>\n",
       "      <th>Founded</th>\n",
       "      <th>HeadQuarter</th>\n",
       "      <th>Sector</th>\n",
       "      <th>What_it_does</th>\n",
       "      <th>Founders</th>\n",
       "      <th>Investor</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unbox Robotics</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>AI startup</td>\n",
       "      <td>Unbox Robotics builds on-demand AI-driven ware...</td>\n",
       "      <td>Pramod Ghadge, Shahid Memon</td>\n",
       "      <td>BEENEXT, Entrepreneur First</td>\n",
       "      <td>$1,200,000</td>\n",
       "      <td>Pre-series A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>upGrad</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>EdTech</td>\n",
       "      <td>UpGrad is an online higher education platform.</td>\n",
       "      <td>Mayank Kumar, Phalgun Kompalli, Ravijot Chugh,...</td>\n",
       "      <td>Unilazer Ventures, IIFL Asset Management</td>\n",
       "      <td>$120,000,000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lead School</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>EdTech</td>\n",
       "      <td>LEAD School offers technology based school tra...</td>\n",
       "      <td>Smita Deorah, Sumeet Mehta</td>\n",
       "      <td>GSV Ventures, Westbridge Capital</td>\n",
       "      <td>$30,000,000</td>\n",
       "      <td>Series D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bizongo</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>B2B E-commerce</td>\n",
       "      <td>Bizongo is a business-to-business online marke...</td>\n",
       "      <td>Aniket Deb, Ankit Tomar, Sachin Agrawal</td>\n",
       "      <td>CDC Group, IDG Capital</td>\n",
       "      <td>$51,000,000</td>\n",
       "      <td>Series C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FypMoney</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>Gurugram</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>FypMoney is Digital NEO Bank for Teenagers, em...</td>\n",
       "      <td>Kapil Banwari</td>\n",
       "      <td>Liberatha Kallat, Mukesh Yadav, Dinesh Nagpal</td>\n",
       "      <td>$2,000,000</td>\n",
       "      <td>Seed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company_Brand  Founded HeadQuarter          Sector  \\\n",
       "0  Unbox Robotics   2019.0   Bangalore      AI startup   \n",
       "1          upGrad   2015.0      Mumbai          EdTech   \n",
       "2     Lead School   2012.0      Mumbai          EdTech   \n",
       "3         Bizongo   2015.0      Mumbai  B2B E-commerce   \n",
       "4        FypMoney   2021.0    Gurugram         FinTech   \n",
       "\n",
       "                                        What_it_does  \\\n",
       "0  Unbox Robotics builds on-demand AI-driven ware...   \n",
       "1     UpGrad is an online higher education platform.   \n",
       "2  LEAD School offers technology based school tra...   \n",
       "3  Bizongo is a business-to-business online marke...   \n",
       "4  FypMoney is Digital NEO Bank for Teenagers, em...   \n",
       "\n",
       "                                            Founders  \\\n",
       "0                        Pramod Ghadge, Shahid Memon   \n",
       "1  Mayank Kumar, Phalgun Kompalli, Ravijot Chugh,...   \n",
       "2                         Smita Deorah, Sumeet Mehta   \n",
       "3            Aniket Deb, Ankit Tomar, Sachin Agrawal   \n",
       "4                                      Kapil Banwari   \n",
       "\n",
       "                                        Investor        Amount         Stage  \n",
       "0                    BEENEXT, Entrepreneur First    $1,200,000  Pre-series A  \n",
       "1       Unilazer Ventures, IIFL Asset Management  $120,000,000          None  \n",
       "2               GSV Ventures, Westbridge Capital   $30,000,000      Series D  \n",
       "3                         CDC Group, IDG Capital   $51,000,000      Series C  \n",
       "4  Liberatha Kallat, Mukesh Yadav, Dinesh Nagpal    $2,000,000          Seed  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading 2021 funds data\n",
    "data_2021 = pd.read_sql_query(\n",
    "    \"SELECT * FROM LP1_startup_funding2021\", connection)\n",
    "\n",
    "# Saving the DataFrame to a CSV file\n",
    "data_2021.to_csv('data/startup_funding2021.csv', index=False)\n",
    "\n",
    "# Data preview\n",
    "data_2021.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 526 entries, 0 to 525\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Company Name   526 non-null    object\n",
      " 1   Industry       526 non-null    object\n",
      " 2   Round/Series   526 non-null    object\n",
      " 3   Amount         526 non-null    object\n",
      " 4   Location       526 non-null    object\n",
      " 5   About Company  526 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 24.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data_2018.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 89 entries, 0 to 88\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Company/Brand  89 non-null     object \n",
      " 1   Founded        60 non-null     float64\n",
      " 2   HeadQuarter    70 non-null     object \n",
      " 3   Sector         84 non-null     object \n",
      " 4   What it does   89 non-null     object \n",
      " 5   Founders       86 non-null     object \n",
      " 6   Investor       89 non-null     object \n",
      " 7   Amount($)      89 non-null     object \n",
      " 8   Stage          43 non-null     object \n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 6.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data_2019.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1055 entries, 0 to 1054\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Company_Brand  1055 non-null   object \n",
      " 1   Founded        842 non-null    float64\n",
      " 2   HeadQuarter    961 non-null    object \n",
      " 3   Sector         1042 non-null   object \n",
      " 4   What_it_does   1055 non-null   object \n",
      " 5   Founders       1043 non-null   object \n",
      " 6   Investor       1017 non-null   object \n",
      " 7   Amount         801 non-null    float64\n",
      " 8   Stage          591 non-null    object \n",
      " 9   column10       2 non-null      object \n",
      "dtypes: float64(2), object(8)\n",
      "memory usage: 82.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data_2020.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1209 entries, 0 to 1208\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Company_Brand  1209 non-null   object \n",
      " 1   Founded        1208 non-null   float64\n",
      " 2   HeadQuarter    1208 non-null   object \n",
      " 3   Sector         1209 non-null   object \n",
      " 4   What_it_does   1209 non-null   object \n",
      " 5   Founders       1205 non-null   object \n",
      " 6   Investor       1147 non-null   object \n",
      " 7   Amount         1206 non-null   object \n",
      " 8   Stage          781 non-null    object \n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 85.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data_2021.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((526, 6), (89, 9), (1055, 10), (1209, 9))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2018.shape, data_2019.shape, data_2020.shape, data_2021.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2879 entries, 0 to 2878\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Company_Brand  2790 non-null   object \n",
      " 1   Founded        2110 non-null   float64\n",
      " 2   HeadQuarter    2765 non-null   object \n",
      " 3   Sector         2861 non-null   object \n",
      " 4   What_it_does   2879 non-null   object \n",
      " 5   Founders       2334 non-null   object \n",
      " 6   Investor       2253 non-null   object \n",
      " 7   Amount         2622 non-null   object \n",
      " 8   Stage          1941 non-null   object \n",
      " 9   Fund_Year      2879 non-null   int64  \n",
      "dtypes: float64(1), int64(1), object(8)\n",
      "memory usage: 225.1+ KB\n"
     ]
    }
   ],
   "source": [
    "def standardize_column_names(df):\n",
    "    # Creating a mapping based on common patterns found in the column names\n",
    "    df.columns = [re.sub(r'(?i)^Company.*Name$', 'Company_Brand', col)\n",
    "                  for col in df.columns]\n",
    "    df.columns = [re.sub(r'(?i)^Amount.*$', 'Amount', col)\n",
    "                  for col in df.columns]\n",
    "    df.columns = [re.sub(r'(?i)^What.*does$', 'What_it_does', col)\n",
    "                  for col in df.columns]\n",
    "    df.columns = [re.sub(r'(?i)^Industry$', 'Sector', col)\n",
    "                  for col in df.columns]\n",
    "    df.columns = [re.sub(r'(?i)^Round.*Series$', 'Stage', col)\n",
    "                  for col in df.columns]\n",
    "    df.columns = [re.sub(r'(?i)^Location$', 'HeadQuarter', col)\n",
    "                  for col in df.columns]\n",
    "    df.columns = [re.sub(r'(?i)^About.*Company$', 'What_it_does', col)\n",
    "                  for col in df.columns]\n",
    "    return df\n",
    "\n",
    "\n",
    "# Applying the function to standardize names\n",
    "data_2018 = standardize_column_names(data_2018)\n",
    "data_2019 = standardize_column_names(data_2019)\n",
    "data_2020 = standardize_column_names(data_2020)\n",
    "data_2021 = standardize_column_names(data_2021)\n",
    "\n",
    "# Ensuring all DataFrames have the same set of columns\n",
    "columns = ['Company_Brand', 'Founded', 'HeadQuarter', 'Sector', 'What_it_does',\n",
    "           'Founders', 'Investor', 'Amount', 'Stage', 'Fund_Year',]\n",
    "\n",
    "# Add a new column 'Fund_Year' to each DataFrame\n",
    "data_2018['Fund_Year'] = 2018\n",
    "data_2019['Fund_Year'] = 2019\n",
    "data_2020['Fund_Year'] = 2020\n",
    "data_2021['Fund_Year'] = 2021\n",
    "\n",
    "data_2018 = data_2018.reindex(columns=columns, fill_value=None)\n",
    "data_2019 = data_2019.reindex(columns=columns)\n",
    "data_2020 = data_2020.reindex(columns=columns)\n",
    "data_2021 = data_2021.reindex(columns=columns)\n",
    "\n",
    "# Merging all DataFrames\n",
    "data = pd.concat([data_2018, data_2019, data_2020,\n",
    "                 data_2021], ignore_index=True)\n",
    "\n",
    "# Saving the DataFrame to a CSV file\n",
    "data.to_csv('data/startup_funding_merged.csv', index=False)\n",
    "\n",
    "# info of the combined DataFrame\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2879, 10)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data\\startup_funding_merged.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Company_Brand, Founded, What_it_does & Investors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trimming white spaces and standardize text format to title case for 'Company_Brand'\n",
    "data['Company_Brand'] = data['Company_Brand'].str.strip().str.title()\n",
    "\n",
    "# Checking for null values in 'Company_Brand'\n",
    "null_company_brand = data['Company_Brand'].isnull().sum()\n",
    "\n",
    "# Replacing null values in 'Company_Brand' with the placeholder \"Unknown\"\n",
    "data['Company_Brand'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Replacing null values in 'Founded' with the median year and ensuring all entries are integers\n",
    "median_year = data['Founded'].median()\n",
    "data['Founded'].fillna(median_year, inplace=True)\n",
    "data['Founded'] = data['Founded'].astype(int)\n",
    "\n",
    "# Trimming white spaces and standardize text format to lower case for 'What_it_does'\n",
    "data['What_it_does'] = data['What_it_does'].str.strip().str.lower()\n",
    "\n",
    "# Trimming white spaces and standardize text format to title case for 'Founders'\n",
    "data['Founders'] = data['Founders'].str.strip().str.title()\n",
    "\n",
    "# Filling null values in 'Founders' with 'Unknown'\n",
    "data['Founders'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Trimming white spaces and standardize text format to title case for 'Investor'\n",
    "data['Investor'] = data['Investor'].str.strip().str.title()\n",
    "\n",
    "# Filling null values in 'Investor' with 'Undisclosed'\n",
    "data['Investor'].fillna('Undisclosed', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Headquarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bangalore', 'Mumbai', 'Gurgaon', 'Noida', 'Hyderabad',\n",
       "       'Bengaluru', 'Kalkaji', 'Delhi', 'India', 'Hubli', 'New Delhi',\n",
       "       'Chennai', 'Mohali', 'Kolkata', 'Pune', 'Jodhpur', 'Kanpur',\n",
       "       'Ahmedabad', 'Azadpur', 'Haryana', 'Cochin', 'Faridabad', 'Jaipur',\n",
       "       'Kota', 'Anand', 'Bangalore City', 'Belgaum', 'Thane', 'Margão',\n",
       "       'Indore', 'Alwar', 'Kannur', 'Trivandrum', 'Ernakulam',\n",
       "       'Kormangala', 'Uttar Pradesh', 'Andheri', 'Mylapore', 'Ghaziabad',\n",
       "       'Kochi', 'Powai', 'Guntur', 'Kalpakkam', 'Bhopal', 'Coimbatore',\n",
       "       'Worli', 'Alleppey', 'Chandigarh', 'Guindy', 'Lucknow', 'Unknown',\n",
       "       'Telangana', 'Gurugram', 'Surat', 'Rajasthan', 'Tirunelveli',\n",
       "       'Singapore', 'Gujarat', 'Kerala', 'Frisco', 'California',\n",
       "       'Dhingsara', 'New York', 'Patna', 'San Francisco', 'San Ramon',\n",
       "       'Paris', 'Plano', 'Sydney', 'San Francisco Bay Area', 'Bangaldesh',\n",
       "       'London', 'Milano', 'Palmwoods', 'France', 'Samastipur', 'Irvine',\n",
       "       'Tumkur', 'Newcastle Upon Tyne', 'Shanghai', 'Jiaxing', 'Rajastan',\n",
       "       'Ludhiana', 'Dehradun', 'San Franciscao', 'Tangerang', 'Berlin',\n",
       "       'Seattle', 'Riyadh', 'Seoul', 'Bangkok', 'Warangal', 'Hyderebad',\n",
       "       'Odisha', 'Bihar', 'Goa', 'Tamil Nadu', 'Banglore', 'Ahmadabad',\n",
       "       'Small Towns', 'Rajsamand', 'Ranchi', 'Computer Games', 'Vadodara',\n",
       "       'Food & Beverages', 'Pharmaceuticals\\t#Ref!', 'Gurugram\\t#Ref!',\n",
       "       'Nagpur', 'West Bengal', 'Samsitpur', 'Silvassa',\n",
       "       'Thiruvananthapuram', 'Roorkee', 'Ambernath', 'Panchkula',\n",
       "       'Mangalore', 'Telugana', 'Bhubaneswar', 'Kottayam', 'Beijing',\n",
       "       'Panaji', 'Satara', 'Orissia', 'Santra', 'Mountain View',\n",
       "       'Jharkhand', 'Bhilwara', 'Guwahati', 'Online Media\\t#Ref!',\n",
       "       'Information Technology & Services', 'The Nilgiris', 'Gandhinagar'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to simplify and standardize headquarters\n",
    "def standardize_headquarters(hq):\n",
    "    if pd.isna(hq):\n",
    "        return \"Unknown\"              # Filling null values with a placeholder\n",
    "    city = hq.split(',')[0].strip()   # Simplifying the entry to city name only\n",
    "    return city.title()               # Converting to title case\n",
    "\n",
    "data['HeadQuarter'] = data['HeadQuarter'].apply(standardize_headquarters)\n",
    "\n",
    "# Check the unique values after cleaning\n",
    "data['HeadQuarter'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bangalore', 'Mumbai', 'Gurgaon', 'Noida', 'Hyderabad', 'Kalkaji',\n",
       "       'Delhi', 'India', 'Hubli', 'New Delhi', 'Chennai', 'Mohali',\n",
       "       'Kolkata', 'Pune', 'Jodhpur', 'Kanpur', 'Ahmedabad', 'Azadpur',\n",
       "       'Haryana', 'Cochin', 'Faridabad', 'Jaipur', 'Kota', 'Anand',\n",
       "       'Belgaum', 'Thane', 'Margão', 'Indore', 'Alwar', 'Kannur',\n",
       "       'Trivandrum', 'Ernakulam', 'Kormangala', 'Uttar Pradesh',\n",
       "       'Andheri', 'Mylapore', 'Ghaziabad', 'Kochi', 'Powai', 'Guntur',\n",
       "       'Kalpakkam', 'Bhopal', 'Coimbatore', 'Worli', 'Alleppey',\n",
       "       'Chandigarh', 'Guindy', 'Lucknow', 'Unknown', 'Telangana', 'Surat',\n",
       "       'Rajasthan', 'Tirunelveli', 'Singapore', 'Gujarat', 'Kerala',\n",
       "       'Frisco', 'California', 'Dhingsara', 'New York', 'Patna',\n",
       "       'San Francisco', 'San Ramon', 'Paris', 'Plano', 'Sydney',\n",
       "       'Bangaldesh', 'London', 'Milano', 'Palmwoods', 'France',\n",
       "       'Samastipur', 'Irvine', 'Tumkur', 'Newcastle Upon Tyne',\n",
       "       'Shanghai', 'Jiaxing', 'Ludhiana', 'Dehradun', 'Tangerang',\n",
       "       'Berlin', 'Seattle', 'Riyadh', 'Seoul', 'Bangkok', 'Warangal',\n",
       "       'Odisha', 'Bihar', 'Goa', 'Tamil Nadu', 'Small Towns', 'Rajsamand',\n",
       "       'Ranchi', 'Vadodara', 'Pharmaceuticals', 'Nagpur', 'West Bengal',\n",
       "       'Samsitpur', 'Silvassa', 'Thiruvananthapuram', 'Roorkee',\n",
       "       'Ambernath', 'Panchkula', 'Mangalore', 'Bhubaneswar', 'Kottayam',\n",
       "       'Beijing', 'Panaji', 'Satara', 'Orissia', 'Santra',\n",
       "       'Mountain View', 'Jharkhand', 'Bhilwara', 'Guwahati',\n",
       "       'The Nilgiris', 'Gandhinagar'], dtype=object)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listing irrelevant entries \n",
    "irrelevant_entries = ['Computer Games', 'Food & Beverages',\n",
    "                      'Online Media', 'Information Technology & Services']\n",
    "\n",
    "# Mapping of common misspellings or variations to standardized city names\n",
    "city_corrections = {\n",
    "    'Bangalore City': 'Bangalore',\n",
    "    'Bengaluru': 'Bangalore',\n",
    "    'Gurugram': 'Gurgaon',\n",
    "    'Noida': 'Noida',\n",
    "    'Hyderebad': 'Hyderabad',\n",
    "    'Banglore': 'Bangalore',\n",
    "    'Ahmadabad': 'Ahmedabad',\n",
    "    'Rajastan': 'Rajasthan',\n",
    "    'San Franciscao': 'San Francisco',\n",
    "    'San Francisco Bay Area': 'San Francisco',\n",
    "    'Telugana': 'Telangana'\n",
    "}\n",
    "\n",
    "# Removing \"\\t#Ref!\" from any entries\n",
    "data['HeadQuarter'] = data['HeadQuarter'].replace(\n",
    "    to_replace=r'\\t#Ref!', value='', regex=True)\n",
    "\n",
    "\n",
    "def correct_city_names(city):\n",
    "    if city in irrelevant_entries:\n",
    "        return \"Unknown\"  # Changing to \"Unknown\" for irrelevant categories\n",
    "    return city_corrections.get(city, city)\n",
    "\n",
    "data['HeadQuarter'] = data['HeadQuarter'].apply(correct_city_names)\n",
    "\n",
    "# Verify the corrections \n",
    "data['HeadQuarter'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define conversion rates for each year\n",
    "conversion_rates = {\n",
    "    2018: 0.01482,\n",
    "    2019: 0.01434,\n",
    "    2020: 0.01331,\n",
    "    2021: 0.01378\n",
    "}\n",
    "\n",
    "# Optimized function to clean and convert Amount values\n",
    "def clean_amount(amount, year):\n",
    "    # Ensure the amount is treated as a string\n",
    "    if pd.isnull(amount):\n",
    "        return 0\n",
    "    amount = str(amount).strip()\n",
    "    # Handle specific non-numeric strings\n",
    "    if amount in ['-', '—', '--', 'Undisclosed', 'Undisclosed ']:\n",
    "        return 0\n",
    "    # Remove currency symbols and commas\n",
    "    amount = amount.replace(',', '').replace('$', '').replace('₹', '')\n",
    "    try:\n",
    "        # Convert based on year if it's in rupees\n",
    "        if '₹' in amount:\n",
    "            return float(amount) * conversion_rates[year]\n",
    "        # Otherwise, assume it's already in dollars\n",
    "        return float(amount)\n",
    "    except ValueError:\n",
    "        # If conversion fails, return 0\n",
    "        return 0\n",
    "\n",
    "# Apply the cleaning function to the Amount column\n",
    "data['Amount'] = data.apply(lambda row: clean_amount(\n",
    "    row['Amount'], row['Fund_Year']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Seed', 'Series A', 'Angel', 'Series B', 'Pre-Seed',\n",
       "       'Private Equity', 'Venture - Series Unknown', 'Grant',\n",
       "       'Debt Financing', 'Post-IPO Debt', 'Series H', 'Series C',\n",
       "       'Series E', 'Corporate Round', 'Undisclosed',\n",
       "       'https://docs.google.com/spreadsheets/d/1x9ziNeaz6auNChIHnMI8U6kS7knTr3byy_YBGfQaoUA/edit#gid=1861303593',\n",
       "       'Series D', 'Secondary Market', 'Post-IPO Equity',\n",
       "       'Non-equity Assistance', 'Funding Round', nan, 'Fresh funding',\n",
       "       'Pre series A', 'Series G', 'Post series A', 'Seed funding',\n",
       "       'Seed fund', 'Series F', 'Series B+', 'Seed round', 'Pre-series A',\n",
       "       'Pre-seed', 'Pre-series', 'Debt', 'Pre-series C', 'Pre-series B',\n",
       "       'Bridge', 'Series B2', 'Pre- series A', 'Edge', 'Pre-Series B',\n",
       "       'Seed A', 'Series A-1', 'Seed Funding', 'Pre-seed Round',\n",
       "       'Seed Round & Series A', 'Pre Series A', 'Pre seed Round',\n",
       "       'Angel Round', 'Pre series A1', 'Series E2', 'Seed Round',\n",
       "       'Bridge Round', 'Pre seed round', 'Pre series B', 'Pre series C',\n",
       "       'Seed Investment', 'Series D1', 'Mid series', 'Series C, D',\n",
       "       '$1200000', 'Seed+', 'Series F2', 'Series A+', 'Series B3', 'PE',\n",
       "       'Series F1', 'Pre-series A1', '$300000', 'Early seed', '$6000000',\n",
       "       '$1000000', 'Seies A', 'Series A2', 'Series I'], dtype=object)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Stage'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "929"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Stage'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Seed', 'Series A', 'Pre-Seed', 'Series B', 'PE', 'Venture',\n",
       "       'Grant', 'Debt', 'Post-IPO', 'Series H', 'Series C', 'Series E',\n",
       "       'Other', 'Unknown', 'Series D', 'Pre-Series A', 'Series G',\n",
       "       'Post-Series A', 'Series F', 'Pre-Series C', 'Pre-Series B',\n",
       "       'Series I'], dtype=object)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary for mapping stages to standardized terms\n",
    "stage_mapping = {\n",
    "    r'(?i)^angel$': 'Pre-Seed',\n",
    "    r'(?i)^seed (funding|fund|round|investment|a|\\+)?$': 'Seed',\n",
    "    r'(?i)^pre[-\\s]?seed( round)?$': 'Pre-Seed',\n",
    "    r'(?i)^pre[-\\s]?series[-\\s]?a1?$': 'Pre-Series A',\n",
    "    r'(?i)^pre[-\\s]?series[-\\s]?a$': 'Pre-Series A',\n",
    "    r'(?i)^pre- series a$': 'Pre-Series A',\n",
    "    r'(?i)^pre[-\\s]?series[-\\s]?b$': 'Pre-Series B',\n",
    "    r'(?i)^pre[-\\s]?series[-\\s]?c$': 'Pre-Series C',\n",
    "    r'(?i)^early seed$': 'Pre-Seed',\n",
    "    r'(?i)^series a[-\\s]?[1+2]?$': 'Series A',\n",
    "    r'(?i)^series b[-\\s]?[+2-3]?$': 'Series B',\n",
    "    r'(?i)^series c, d$': 'Series C',\n",
    "    r'(?i)^series d1$': 'Series D',\n",
    "    r'(?i)^series e2$': 'Series E',\n",
    "    r'(?i)^series f[1-2]?$': 'Series F',\n",
    "    r'(?i)^venture - series unknown$': 'Venture',\n",
    "    r'(?i)^post series a$': 'Post-Series A',\n",
    "    r'(?i)^non-equity assistance$': 'Other',\n",
    "    r'(?i)^corporate round$': 'Other',\n",
    "    r'(?i)^bridge( round)?$': 'Other',\n",
    "    r'(?i)^private equity$': 'PE',\n",
    "    r'(?i)^secondary market$': 'Other',\n",
    "    r'(?i)^debt financing$': 'Debt',\n",
    "    r'(?i)^post-ipo (debt|equity)$': 'Post-IPO',\n",
    "    r'(?i)^undisclosed$': 'Other',\n",
    "    r'(?i)^funding round$': 'Other',\n",
    "    r'(?i)^fresh funding$': 'Other',\n",
    "    r'(?i)^mid series$': 'Other',\n",
    "    r'(?i)^edge$': 'Other',\n",
    "    r'(?i)^grant$': 'Grant',\n",
    "    r'(?i)^seies a$': 'Series A',\n",
    "    r'(?i)^pre[-\\s]?series$': 'Pre-Seed',\n",
    "    r'(?i)^angel round$': 'Pre-Seed',\n",
    "    r'(?i)^seed round & series a$': 'Seed',\n",
    "    r'(?i)^series i$': 'Series I'\n",
    "}\n",
    "\n",
    "# Applying the mappings using regular expressions\n",
    "for pattern, replacement in stage_mapping.items():\n",
    "    data['Stage'] = data['Stage'].str.replace(pattern, replacement, regex=True)\n",
    "\n",
    "data['Stage'] = data['Stage'].str.replace(r'(?i)seed\\+', 'Seed', regex=True)\n",
    "\n",
    "# Replacing numeric and erroneous entries with 'Unknown'\n",
    "data['Stage'] = data['Stage'].replace(\n",
    "    r'\\$\\d+', 'Unknown', regex=True)  # Catch dollar amounts\n",
    "data['Stage'] = data['Stage'].replace(\n",
    "    r'https?://\\S+', 'Unknown', regex=True)  # Catch URLs\n",
    "\n",
    "# Handle NaN values\n",
    "data['Stage'].fillna('Unknown', inplace=True)\n",
    "\n",
    "\n",
    "data['Stage'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category\n",
       " technology                        1354\n",
       " fintech                            360\n",
       " education and training             262\n",
       " e-commerce                         159\n",
       " mobility and transportation        112\n",
       " media and entertainment            106\n",
       " food and beverages                 104\n",
       " Other                               49\n",
       " business services                   39\n",
       " real estate                         39\n",
       " consumer goods and services         37\n",
       " financial services                  36\n",
       " design and creative industries      34\n",
       " beauty and wellness                 33\n",
       " renewable energy                    22\n",
       " consumer services                   20\n",
       " healthcare                          16\n",
       " travel                              15\n",
       " consumer goods                      15\n",
       " sports technology                   12\n",
       " technology and innovation           12\n",
       " events and entertainment            10\n",
       " human resources                     10\n",
       " Name: count, dtype: int64,\n",
       " array(['other', 'Other', 'manchester greater manchester'], dtype=object))"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comprehensive mappings and sector categories (redefined here for completeness)\n",
    "comprehensive_mappings = {\n",
    "    'fintech': 'financial services', 'credit': 'financial services', 'lending': 'financial services',\n",
    "    'saas': 'software as a service', 'ecommerce': 'e-commerce', 'ecommerce platforms': 'e-commerce',\n",
    "    'retail': 'e-commerce', 'marketing': 'brand marketing', 'event promotion': 'brand marketing',\n",
    "    'tech': 'technology', 'tech company': 'technology', 'tech platform': 'technology',\n",
    "    'tech startup': 'technology', 'cloud computing computer saas software': 'software as a service',\n",
    "    'software company': 'software', 'software startup': 'software',\n",
    "    'cloud computing computer software': 'software', 'cloud computing enterprise software': 'software',\n",
    "    'cloud infrastructure paas saas': 'software as a service', 'edtech': 'education',\n",
    "    'elearning': 'education', 'higher education': 'education', 'health care': 'health & wellness',\n",
    "    'wellness': 'health & wellness', 'medical': 'health & wellness', 'healthcare services': 'health & wellness',\n",
    "    'social commerce': 'e-commerce', 'social ecommerce': 'e-commerce', 'online portals': 'e-commerce',\n",
    "    'startup': 'startups', 'startup laboratory': 'startups', 'real estate': 'property',\n",
    "    'commercial real estate': 'property', 'coworking': 'property',\n",
    "    'communities coworking incubators': 'property', 'commercial real estate coworking office administration real estate': 'property',\n",
    "    'transport': 'transportation', 'transport automation': 'transportation', 'transport rentals': 'transportation',\n",
    "    'travel tech': 'travel', 'travel saas': 'travel', 'traveltech': 'travel', 'virtual banking': 'financial services',\n",
    "    'banking': 'financial services', 'ai': 'artificial intelligence'\n",
    "}\n",
    "sector_categories = {\n",
    "    'Technology': ['artificial intelligence', 'cloud computing', 'software', 'software as a service'],\n",
    "    'E-commerce': ['e-commerce', 'social commerce', 'online portals'],\n",
    "    'Fintech': ['financial services'],\n",
    "    'Healthcare': ['health & wellness'],\n",
    "    'Education': ['education'],\n",
    "    'Real Estate': ['property'],\n",
    "    'Transportation': ['transportation'],\n",
    "    'Travel': ['travel'],\n",
    "    'Startups': ['startups']\n",
    "}\n",
    "\n",
    "\n",
    "def clean_and_categorize(sector):\n",
    "    if pd.isna(sector):\n",
    "        return sector, 'Other'\n",
    "\n",
    "    # Clean sector description\n",
    "    sector = sector.lower()\n",
    "    sector = re.sub(r'[^\\w\\s]', '', sector)\n",
    "    sector = re.sub(r'\\s+', ' ', sector).strip()\n",
    "\n",
    "    # Apply mappings and categorize\n",
    "    mapped_sector = comprehensive_mappings.get(sector, sector)\n",
    "    for category, keywords in sector_categories.items():\n",
    "        if any(keyword in mapped_sector for keyword in keywords):\n",
    "            return mapped_sector, category\n",
    "    return mapped_sector, 'Other'\n",
    "\n",
    "\n",
    "# Apply cleaning and categorization function to the \"Sector\" column\n",
    "data[['Sector', 'Category']] = data['Sector'].apply(\n",
    "    lambda x: pd.Series(clean_and_categorize(x)))\n",
    "\n",
    "# Mapping dictionary based on the user's specified categories\n",
    "category_mapping = {\n",
    "    'technology': ['software', 'ai', 'artificial intelligence', 'iot', 'internet of things', 'machine learning', 'tech', 'saas', 'cloud computing', 'software as a service', 'blockchain'],\n",
    "    'e-commerce': ['e-commerce', 'online shopping', 'online market', 'online retail', 'ecommerce'],\n",
    "    'fintech': ['fintech', 'digital payment', 'personal finance', 'insurtech', 'investment platform', 'banking', 'financial services'],\n",
    "    'healthcare': ['telemedicine', 'biotechnology', 'pharmaceuticals', 'health analytics', 'health & wellness', 'medical', 'healthcare'],\n",
    "    'education': ['edtech', 'e-learning', 'online courses', 'learning management system', 'educational technology'],\n",
    "    'agriculture': ['agriculture', 'agritech', 'precision farming', 'farm management software'],\n",
    "    'renewable energy': ['renewable energy', 'solar', 'wind energy', 'cleantech'],\n",
    "    'food and beverages': ['food processing', 'health-centric products', 'food delivery', 'catering', 'food and beverage'],\n",
    "    'mobility and transportation': ['electric vehicle', 'ride-sharing', 'logistics', 'transportation'],\n",
    "    'retail': ['retail', 'virtual reality shopping', 'retail analytics', 'customer engagement'],\n",
    "    'real estate': ['real estate', 'property management', 'real estate investment', 'virtual tours', 'property'],\n",
    "    'manufacturing': ['digital manufacturing', 'robotics', 'manufacturing', 'supply chain optimization'],\n",
    "    'tourism and hospitality': ['tourism', 'hospitality', 'travel tech', 'booking platform', 'experiential travel'],\n",
    "    'media and entertainment': ['media', 'entertainment', 'digital media', 'streaming services', 'content creation', 'gaming'],\n",
    "    'sports technology': ['sports', 'sports analytics', 'athlete performance tracking', 'fan engagement'],\n",
    "    'beauty and wellness': ['beauty', 'cosmetics', 'wellness', 'wellness apps', 'personalized beauty solutions'],\n",
    "    'legal tech': ['legal tech', 'legal processes', 'document management', 'client services'],\n",
    "    'human resources': ['human resources', 'recruitment', 'employee engagement', 'performance management'],\n",
    "    'cybersecurity': ['cybersecurity', 'network security', 'risk management'],\n",
    "    'space technology': ['space technology', 'satellite communications', 'space exploration']\n",
    "}\n",
    "\n",
    "\n",
    "def map_sector_to_category(sector):\n",
    "    if pd.isna(sector):\n",
    "        return 'Other'  # Handle NaN values explicitly\n",
    "    sector = sector.lower()\n",
    "    for category, keywords in category_mapping.items():\n",
    "        if any(keyword in sector for keyword in keywords):\n",
    "            return category\n",
    "    return 'Other'  # Default category if no match is found\n",
    "\n",
    "\n",
    "# Apply the new mapping to the 'Sector' column\n",
    "data['Category'] = data['Sector'].apply(map_sector_to_category)\n",
    "\n",
    "# Update the mapping dictionary to incorporate the new adjustments\n",
    "category_mapping.update({\n",
    "    'media and entertainment': category_mapping['media and entertainment'] + ['advertising', 'marketing', 'digital marketing'],\n",
    "    'mobility and transportation': category_mapping['mobility and transportation'] + ['automobile', 'automobiles', 'automotive', 'autonomous vehicles', 'aviation', 'aerospace'],\n",
    "    'business services': ['b2b', 'advisory', 'consulting', 'service industry', 'business development'],\n",
    "    'healthcare': category_mapping['healthcare'] + ['alternative medicine', 'mhealth', 'health apps', 'pharmaceutical apps'],\n",
    "    'technology': category_mapping['technology'] + ['ar', 'vr', 'augmented reality', 'virtual reality', 'api platform']\n",
    "})\n",
    "\n",
    "# Function to map sectors to categories with updated mappings\n",
    "\n",
    "\n",
    "def map_sector_to_updated_category(sector):\n",
    "    if pd.isna(sector):\n",
    "        return 'Other'\n",
    "    sector = sector.lower()\n",
    "    for category, keywords in category_mapping.items():\n",
    "        if any(keyword in sector for keyword in keywords):\n",
    "            return category\n",
    "    return 'Other'\n",
    "\n",
    "\n",
    "# Reapply the mapping to the 'Sector' column\n",
    "data['Category'] = data['Sector'].apply(map_sector_to_updated_category)\n",
    "\n",
    "# Update the category mapping dictionary to incorporate additional groupings\n",
    "category_mapping.update({\n",
    "    'accommodation and rental services': ['accommodation', 'bike rental', 'coliving', 'rental services'],\n",
    "    'consumer goods and services': ['appliance', 'clothing', 'consumer electronics', 'consumer goods', 'eyeglasses'],\n",
    "    'design and creative industries': ['design', 'deisgning', 'fashion', 'fashion and lifestyle'],\n",
    "    'energy and environmental services': ['energy', 'energy storage', 'environmental service', 'environmental services'],\n",
    "    'financial services': category_mapping['fintech'] + ['finance', 'finance company', 'digital mortgage', 'escrow'],\n",
    "    'technology': category_mapping['technology'] + ['analytics', 'data analytics', 'data science', 'automation', 'drone', 'crypto', 'cryptocurrency']\n",
    "})\n",
    "\n",
    "# Reapply the updated mapping to further reduce the 'Other' category\n",
    "data['Category'] = data['Sector'].apply(map_sector_to_updated_category)\n",
    "\n",
    "# Update the category mapping dictionary to incorporate the latest insights\n",
    "category_mapping.update({\n",
    "    'consumer services': category_mapping.get('consumer services', []) + ['consumer service', 'consumer services', 'customer service company', 'customer service messaging', 'home services', 'health diagnostics', 'hospital services', 'hygiene management'],\n",
    "    'education and training': category_mapping.get('education', []) + ['education', 'education management', 'children education online portals'],\n",
    "    'events and entertainment': ['events', 'celebrity engagement', 'entertainment management', 'cultural events'],\n",
    "    'food and beverages': category_mapping['food and beverages'] + ['beverage', 'beverages', 'food beverages', 'food production', 'food nutrition', 'food industry'],\n",
    "    'technology and innovation': category_mapping['technology'] + ['apps', 'battery', 'electronics', 'data intelligence', 'emobility', 'innovation management'],\n",
    "    'health and wellness': category_mapping.get('healthcare', []) + ['health', 'health and fitness', 'health diagnostics', 'health insurance'],\n",
    "    'dating and social networking': ['dating', 'dating app', 'dating private social networking'],\n",
    "    'e-commerce and retail': category_mapping['e-commerce'] + ['e store', 'econnect', 'commerce', 'd2c', 'd2c business']\n",
    "})\n",
    "\n",
    "# Function to map sectors to categories with updated mappings\n",
    "\n",
    "\n",
    "def map_sector_to_final_category(sector):\n",
    "    if pd.isna(sector):\n",
    "        return 'Other'\n",
    "    sector = sector.lower()\n",
    "    for category, keywords in category_mapping.items():\n",
    "        if any(keyword in sector for keyword in keywords):\n",
    "            return category\n",
    "    return 'Other'\n",
    "\n",
    "\n",
    "# Reapply the mapping to the 'Sector' column to reduce the 'Other' category\n",
    "data['Category'] = data['Sector'].apply(map_sector_to_final_category)\n",
    "\n",
    "# Adjust the function to handle NaN values before applying text corrections\n",
    "\n",
    "\n",
    "def correct_sector_misspellings(sector):\n",
    "    if pd.isna(sector):\n",
    "        return sector  # Return NaN as is\n",
    "    corrections = {\n",
    "        'accomodation': 'accommodation',\n",
    "        'aeorspace': 'aerospace',\n",
    "        'companyasaservice': 'company as a service',\n",
    "        'entreprenurship': 'entrepreneurship',\n",
    "        'estore': 'e-store',\n",
    "        'food devlivery': 'food delivery'\n",
    "    }\n",
    "    sector = sector.lower()\n",
    "    # Apply corrections\n",
    "    for incorrect, correct in corrections.items():\n",
    "        sector = sector.replace(incorrect, correct)\n",
    "    return sector\n",
    "\n",
    "\n",
    "# Reapply corrections to the 'Sector' column\n",
    "data['Sector'] = data['Sector'].apply(correct_sector_misspellings)\n",
    "\n",
    "# Reapply the mapping to the corrected 'Sector' column\n",
    "data['Category'] = data['Sector'].apply(map_sector_to_final_category)\n",
    "\n",
    "# Further refine the category mappings based on the additional analysis\n",
    "category_mapping.update({\n",
    "    'technology': category_mapping['technology'] + ['internet', 'mobile payments', 'mobile', 'it', 'digital platform', 'podcast', 'video communication', 'mobile games', 'video personalization'],\n",
    "    'financial services': category_mapping['financial services'] + ['trading platform', 'wealth management', 'investment', 'investment management', 'venture capital', 'venture capital private equity'],\n",
    "    'healthcare': category_mapping['healthcare'] + ['hospital', 'nutrition', 'fitness', 'health diagnostics', 'hygiene', 'life sciences'],\n",
    "    'consumer services': category_mapping['consumer services'] + ['rental', 'housing', 'housing rentals', 'consultancy', 'home decor', 'home interior services', 'furniture', 'furniture rental'],\n",
    "    'media and entertainment': category_mapping['media and entertainment'] + ['music streaming', 'music', 'social audio', 'content publishing', 'social platform', 'blogging', 'publication', 'podcast'],\n",
    "    'events and entertainment': category_mapping['events and entertainment'] + ['wedding', 'matrimony', 'events', 'cultural'],\n",
    "    'food and beverages': category_mapping['food and beverages'] + ['craft beer', 'food diet'],\n",
    "    'legal services': ['legal', 'legal services', 'legal processes'],\n",
    "    'real estate': category_mapping['real estate'] + ['interior decor', 'housing'],\n",
    "    'transportation': category_mapping['mobility and transportation'] + ['ev', 'mobilitytransport', 'micromobiity'],\n",
    "    'business services': category_mapping['business services'] + ['business supplies equipment', 'crm', 'customer service company', 'customer service messaging', 'consultancy', 'company as a service', 'product studio', 'staffing recruiting'],\n",
    "    'renewable energy': category_mapping['renewable energy'] + ['renewables environment', 'water purification', 'pollution control equipment'],\n",
    "    'education and training': category_mapping['education and training'] + ['job discovery platform', 'skill development', 'online storytelling'],\n",
    "    'consumer goods': category_mapping['consumer goods and services'] + ['furniture rental', 'merchandise', 'textiles', 'fmcg']\n",
    "})\n",
    "\n",
    "# Reapply the mapping to the corrected 'Sector' column\n",
    "data['Category'] = data['Sector'].apply(map_sector_to_final_category)\n",
    "\n",
    "# Further refine the category mappings based on the additional analysis\n",
    "category_mapping.update({\n",
    "    'technology': category_mapping['technology'] + [\n",
    "        'cloud company', 'video streaming platform', 'scanning app', 'video platform', 'video', 'computer games',\n",
    "        'mlops platform', 'networking platform', 'networking', 'telecommunication', 'telecommunications', 'online financial service', 'information services'\n",
    "    ],\n",
    "    'financial services': category_mapping['financial services'] + [\n",
    "        'insurance', 'mutual funds', 'wl rac protection', 'taxation'\n",
    "    ],\n",
    "    'media and entertainment': category_mapping['media and entertainment'] + [\n",
    "        'video', 'video streaming platform', 'video platform', 'fm', 'multinational conglomerate company', 'social network', 'ott', 'sochcast is an audio experiences company that give the listener and creators an immersive audio experience'\n",
    "    ],\n",
    "    'business services': category_mapping['business services'] + [\n",
    "        'packaging services', 'work fulfillment', 'sales services', 'sales and distribution', 'entrepreneurship', 'job portal', 'content management'\n",
    "    ],\n",
    "    'consumer goods': category_mapping['consumer goods'] + [\n",
    "        'consumer', 'jewellery', 'lifestyle', 'wholesale', 'tobacco', 'hauz khas', 'delivery service', 'pollution control equipment', 'fishery', 'mechanical or industrial engineering'\n",
    "    ],\n",
    "    'healthcare': category_mapping['healthcare'] + ['medical'],\n",
    "    'real estate': category_mapping['real estate'] + [\n",
    "        'housing', 'nano distribution network', 'home interior services', 'interior decor'\n",
    "    ],\n",
    "    'events and entertainment': category_mapping['events and entertainment'] + [\n",
    "        'games', 'advertisement', 'defense space', 'nft', 'content publishing', 'advertisement'\n",
    "    ],\n",
    "    'energy and environmental services': category_mapping['energy and environmental services'] + [\n",
    "        'renewable player', 'pollution control equipment'\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Reapply the mapping to the corrected 'Sector' column\n",
    "data['Category'] = data['Sector'].apply(map_sector_to_final_category)\n",
    "\n",
    "# Function to correct the remaining misspellings and standardize terms within the sectors\n",
    "\n",
    "\n",
    "def correct_final_sector_misspellings(sector):\n",
    "    corrections = {\n",
    "        'telecommuncation': 'telecommunication',\n",
    "        'pollution control equiptment': 'pollution control equipment'\n",
    "    }\n",
    "    if pd.isna(sector):\n",
    "        return sector  # Return NaN as is\n",
    "    sector = sector.lower()\n",
    "    # Apply corrections\n",
    "    for incorrect, correct in corrections.items():\n",
    "        sector = sector.replace(incorrect, correct)\n",
    "    return sector\n",
    "\n",
    "\n",
    "# Reapply corrections to the 'Sector' column\n",
    "data['Sector'] = data['Sector'].apply(correct_final_sector_misspellings)\n",
    "\n",
    "# Expand categories to accommodate remaining sectors\n",
    "category_mapping.update({\n",
    "    'technology': category_mapping['technology'] + ['crowdsourcing'],\n",
    "    'transportation': category_mapping['mobility and transportation'] + ['tyre management'],\n",
    "    'aerospace': ['aero company'],\n",
    "    'construction': ['construction'],\n",
    "    'human resources': category_mapping['human resources'] + ['hr'],\n",
    "    'e-commerce': category_mapping['e-commerce'] + ['e-store'],\n",
    "    'mechanical engineering': ['mechanical industrial engineering'],\n",
    "    'travel': ['travel'],\n",
    "    'pollution control': ['pollution control equipment'],\n",
    "    'localization services': ['translation localization'],\n",
    "    'regional': ['manchester greater manchester']\n",
    "})\n",
    "\n",
    "# Reapply the mapping to the corrected 'Sector' column\n",
    "data['Category'] = data['Sector'].apply(map_sector_to_final_category)\n",
    "\n",
    "# Replace empty values in the 'Sector' column with 'Unknown'\n",
    "data['Sector'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Reapply the mapping to the 'Sector' column after replacing empty values\n",
    "data['Category'] = data['Sector'].apply(map_sector_to_final_category)\n",
    "\n",
    "# Function to re-categorize the remaining sectors in 'Other'\n",
    "\n",
    "\n",
    "def finalize_other_category(sector):\n",
    "    if sector == 'food':\n",
    "        return 'food and beverages'\n",
    "    elif sector == 'ev':\n",
    "        return 'mobility and transportation'\n",
    "    elif sector == '' or sector == 'unknown':\n",
    "        return 'Other'\n",
    "    return sector\n",
    "\n",
    "\n",
    "# Apply final adjustments to the 'Sector' column\n",
    "data['Sector'] = data['Sector'].apply(finalize_other_category)\n",
    "\n",
    "# Reapply the mapping to the 'Sector' column after final adjustments\n",
    "data['Category'] = data['Sector'].apply(map_sector_to_final_category)\n",
    "\n",
    "# Function to merge small categories into broader ones\n",
    "\n",
    "\n",
    "def merge_small_categories(category):\n",
    "    if category == 'manufacturing':\n",
    "        return 'technology'\n",
    "    elif category == 'e-commerce and retail':\n",
    "        return 'e-commerce'\n",
    "    elif category == 'health and wellness':\n",
    "        return 'healthcare'\n",
    "    elif category == 'energy and environmental services':\n",
    "        return 'renewable energy'\n",
    "    elif category == 'accommodation and rental services':\n",
    "        return 'real estate'\n",
    "    elif category == 'construction':\n",
    "        return 'real estate'\n",
    "    elif category == 'tourism and hospitality':\n",
    "        return 'travel'\n",
    "    elif category == 'dating and social networking':\n",
    "        return 'media and entertainment'\n",
    "    elif category == 'legal services':\n",
    "        return 'business services'\n",
    "    elif category == 'agriculture':\n",
    "        return 'food and beverages'\n",
    "    elif category == 'aerospace':\n",
    "        return 'technology'\n",
    "    elif category == 'transportation':\n",
    "        return 'mobility and transportation'\n",
    "    elif category == 'mechanical engineering':\n",
    "        return 'technology'\n",
    "    elif category == 'localization services':\n",
    "        return 'business services'\n",
    "    elif category == 'regional':\n",
    "        return 'Other'\n",
    "    return category\n",
    "\n",
    "\n",
    "# Apply the merging function to the 'Category' column\n",
    "data['Category'] = data['Category'].apply(merge_small_categories)\n",
    "\n",
    "# Check the updated distribution of categories after merging small categories\n",
    "final_category_counts_after_merging_small = data['Category'].value_counts()\n",
    "final_remaining_other_sectors = data[data['Category']\n",
    "                                     == 'Other']['Sector'].dropna().unique()\n",
    "\n",
    "final_category_counts_after_merging_small, final_remaining_other_sectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the DataFrame to a CSV file\n",
    "data.to_csv('data/cleaned_startup_funding.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Business Questions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The year-on-year growth in total funding received by Indian start-ups from 2018 to 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
